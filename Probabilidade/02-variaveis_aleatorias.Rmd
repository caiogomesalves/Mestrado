---
title: "Notas de Aula - Capítulo 2"
subtitle: "Probabilidade"
author: "Caio Gomes Alves"
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{tikz}
   - \usepackage{pgfplots}
   - \usepackage{caption}
   - \usepackage{subcaption}
   - \usepackage{cancel}
   - \usepackage{mathtools}
   - \usepackage{annotate-equations}
output:
  bookdown::pdf_document2:
    toc: false
---

# Variáveis Aleatórias

## Variáveis aleatórias e funções de distribuição

::: {.example}

Considere um experimento em que uma moeda é lançada duas vezes. Seja $X =$ total de caras nos dois lançamentos. Denotemos o evento cara como $H$ e coroa como $T$. Logo:

\begin{center}
\begin{tabular}{|c|c|} \toprule
Espaço Amostral ($\Omega$) & $X$ \\ \midrule
HT & 1 \\
TH & 1 \\
HH & 2 \\
TT & 0 \\ \bottomrule
\end{tabular}
\end{center}

Logo, $X:\mathcal{F} \to \mathbb{R}$. Vale também que, $\forall x$ valor na imagem de $X$, $X^{-1}(x) \in \mathcal{F}$. Por exemplo:

\begin{align*}
x = 1 &\Rightarrow X^{-1}(1) = \{HT,TH\} \\
x = 2 &\Rightarrow X^{-1}(2) = \{HH\} \\
x = 0 &\Rightarrow X^{-1}(0) = \{TT\} \\
\end{align*}

:::

::: {.definition name="Variável aleatória"}

Seja $(\Omega,\mathcal{F},P)$ um espaço de probabilidades. Uma função $X:\mathcal{F} \to \mathbb{R}$ é variável aleatória se $[x \in I] \in \mathcal{F}, \; I \in \mathbb{R}$ (ou, equivalentemente, se $\{\omega:X(\omega) \in I\} \in \mathcal{F}; \; X^{-1}(I) \in \mathcal{F}$).

:::

::: {.definition name="Distribuição Acumulada"}

Considere um espaço de probabilidades $(\Omega,\mathcal{F},P)$ e $X:\mathcal{F} \to \mathbb{R}$ uma variável aleatória, defina $F(r) = P(X \le r) = P(\{\omega : X(\omega) \le r\})$.

:::

::: {.example}

Seja $X =$ número de caras em dois lançamentos de moeda (honesta). Temos que as probabilidades de $X$ são dadas por:

\begin{align*}
P(X = 0) &= P(\{TT\}) = \frac{1}{4} \\
P(X = 1) &= P(\{TH,HT\}) = \frac{2}{4} \\
P(X = 2) &= P(\{HH\}) = \frac{1}{4}
\end{align*}

Para encontrarmos a função de distribuição acumulada, podemos particinar o espaço e "acumular" as probabilidades. Para $r < 0$:

\begin{equation*}
F(r) = P([X \le r]) = P(\emptyset) = 0
\end{equation*}

Para $r \in [0,1)$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 0) = \frac{1}{4}
\end{equation*}

Para $r \in [1,2)$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 1) = P(X = 0) + P(X = 1) = \frac{3}{4}
\end{equation*}

Para $r \ge 2$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 2) = P(X = 0) + P(X = 1) + P(X = 2) = 1
\end{equation*}

Logo, $F$ é dada por:

\begin{equation*}
F(r) = \begin{cases} 0, & r<0 \\ \frac{1}{4}, & r \in [0,1) \\ \frac{3}{4}, & r \in [1,2) \\ 1, & r \ge 2 \end{cases}
\end{equation*}

\pgfplotsset{
  graf1/.style={
    xlabel=$X$,
    width=10cm, height=7cm,
    mark=*,
    nodes near coords,
    point meta=explicit symbolic, % permite usar a 3 coluna como label.
    every node near coord/.append style={font=\footnotesize},
    nodes near coords align={vertical}
  }
}

\pgfplotstableread{
  i    x   px   PX   f  F
  1    0 0.25 0.25 1/4 1/4
  2    1 0.50 0.75 2/4 3/4
  3    2 0.25 1.00 1/4 4/4
}\distrprob

\begin{center}
\begin{tikzpicture}[domain=0:2]
    \begin{axis}[
      graf1,
      grid=major,
      ytick distance=0.25,
      ymin=-0.1,
      ymax=1.2,
      ylabel={$P(X \le r)$},
      title={Distribui\c{c}\~{a}o de probabilidades acumulada}]
      \addplot[thick, black, const plot, jump mark left]
      table[x=x, y=PX, meta=F] \distrprob;
      \draw[black] (axis cs: -1, 0) -- (axis cs: 0, 0);
      \draw[black] (axis cs: 2, 1) -- (axis cs: 3, 1);
    \end{axis}
\end{tikzpicture}
\end{center}

:::

::: {.theorem name="Propriedades da distribuição acumulada"}

Seja $X$ uma variável aleatória definida em $(\Omega,\mathcal{F},P)$, então a f.d.a. de $X$ ($F_{X}$ ou $F$) verifica:

a) $F$ é monótona não decrescente;
b) $F$ é contínua à direita;
c) $\lim_{t \to - \infty}F(t) = 0$ e $\lim_{t \to \infty}F(t) = 1$.

:::

::: {.proof}

a) Dados $a,b \in \mathbb{R} : a \le b; \; [X \le a] \subseteq [X \le b] \Rightarrow P([X \le a]) \le P([X \le b]) \Rightarrow F(a) \le F(b)$.

b) Se $X_{n}\downarrow x$, quando $n \to \infty$, temos que $\{[X \le x_{n}]\}_{n \ge 1}$ é tal que $\bigcap_{n \ge 1}[X \le x_{n}] = [X \le x]$. Isso significa que $[X \le x]$ acontece se e somente se $[X \le x_{n}] \; \forall n$. Além disso, $[X \le x_{n}] \downarrow [X \le x]$ quando $n \to \infty$, logo, pela continuidade da função de probabilidade $P([X \le x_{n}]) \downarrow P([X \le x]), n \to \infty$.

c) Considere agora que $x_{n} \downarrow -\infty \Rightarrow [X \le x_{n}] \downarrow \emptyset, \; n \to \infty \Rightarrow F(x_{n}) = P([X \le x_{n}]) \downarrow P(\emptyset) = 0, \; n \to \infty$.
Se $x_{n} \uparrow \infty \Rightarrow [X \le x_{n}] \uparrow \Omega, \; n \to \infty \Rightarrow F(x_{n}) = P([X \le x_{n}]) \uparrow P(\Omega) = 1, \; n \to \infty$.

:::

::: {.theorem}

Se $F$ é a f.d.a. da variável aleatória $X$, então:

a) Existem e são finitos os limites laterais $\lim_{t \to r^{-}}F(t), \lim_{t \to r^{+}}F(t), \forall r \in \mathbb{R}$ e $\lim_{t \to r^{-}}F(t) \le \lim_{t \to r^{+}}F(t)$;

b) $\lim_{t \to r^{+}}F(t) = F(r), \forall r \in \mathbb{R}$;

c) $F$ é descontínua em $r, r \in \mathbb{R}$ se e somente se $\lim_{t \to r^{-}}F(t) < F(r)$, com um salto de tamanho $F(r) - \lim_{t \to r^{-}}F(t)$;

d) $\forall r \in \mathbb{R}, P(X = r) = F(r) - \lim_{t \to r^{-}}F(t)$;

e) Existem no máximo um total enumerável de descontinuidades em $F$.

:::

::: {.proof}

a) $F$ é monótona e limitada ($0 \le F \le 1$). Logo, os limites laterais existem e são limitados.

b) Como $F$ é monótona não-decrescente, $\forall x,y : x \le y \Rightarrow F(x) \le F(y)$. Logo $\lim_{t \to r^{-}}F(t) \le \lim_{t \to r^{+}}F(t)$.

c) Como $F$ é monótona não-decrescente, uma descontinuidade só ocorre se e somente se $\lim_{t \to r^{-}}F(t) < \lim_{t \to r^{+}}F(t) = F(r)$.

d) Seja $r \in \mathbb{R}. \; [X \le r] = \bigcap_{n=1}^{\infty}(r-\frac{1}{n} < x \le r)$, logo:

\begin{align*}
P([X = r]) &= P\left(\bigcap_{n=1}^{\infty}\left(r-\frac{1}{n} < x \le r\right)\right) \\
&\Downarrow \text{(Teorema da continuidade)} \\
&=\lim_{n \to \infty}P\left(\left(r - \frac{1}{n} < x \le r\right)\right) \\
&= \lim_{n \to \infty} \left(F(r) - F\left(r - \frac{1}{n}\right)\right) \\
&= F(r) - \lim_{n \to \infty}F\left(r - \frac{1}{n}\right) \\
P([X = r]) &= F(r) - \lim_{t \to r^{-}}F(t)
\end{align*}

e) Seja $\mathcal{D}$ o conjunto de pontos de descontinuidades de $F$, e seja $\lim_{t \to x^{-}}F(t) = F(x^{-})$. Logo:

\begin{equation*}
\mathcal{D} = \{x \in \mathbb{R} : F(x) - F(x^{-}) > 0\}
\end{equation*}

Seja $\mathcal{D}_{n}$ o conjunto de pontos para os quais a amplitude do salto é maior ou igual a $\frac{1}{n}$. Logo:

\begin{equation*}
\mathcal{D}_{n} = \left\{x \in \mathbb{R}: F(x) - F(x^{-}) \ge \frac{1}{n}\right\} \Rightarrow \# D = |D| \le n
\end{equation*}

Se $x \in \mathcal{D} \Rightarrow \exists n_{0} > 1 : F(x) - F(x^{-}) \ge \frac{1}{n_{0}} \Rightarrow x \in \bigcup_{n=1}^{\infty}\mathcal{D}_{n}$. Se $x \in \bigcup_{n=1}^{\infty}\mathcal{D}_{n} \Rightarrow \exists n_{1} : x \in \mathcal{D}_{n} \Rightarrow x \in \mathcal{D}$. $\mathcal{D}$ portanto é a união enumerável de conjuntos finitos, logo é enumerável.

:::

## Natureza das variáveis aleatórias

a) $X$ é uma variável aleatória discreta se os valores que ela toma pertencem a um conjunto enumerável, logo $X:\Omega \to \{x_{1},x_{2},\ldots\}$ (ou seja, $X(\omega) \in \{x_{1},x_{2},\ldots\}, \forall \omega \in \Omega$) e $P: \{x_{1},x_{2},\ldots\} \to [0,1]$ é dado por $P(x_{i}) = P\{\omega : \omega \in \Omega \text{ e } X(\omega) = x_{i}\} \forall i \ge 1$.

b) $X$ é uma variável aleatória absolutamente contínua se $\exists f$ (uma função) tal que $f(x) \ge 0, \forall x \in \mathbb{R}$ e $F_{X}(x) = \int_{-\infty}^{x}f(t) dt$ (onde $f$ é chamada de densidade de $X$).

Sob **(a)** temos que $[X \le x] = \bigcup_{i : x_{i} \le x} [X = x_{i}]$. Logo $F_{x}(x) = \sum_{i : x_{i} \le x}P(x_{i})$.

Sob **(b)** estamos afirmando que $F_{X}$ é a integral de $f$ (ou seja, $f$ é a sua derivada) para todo $x$ exceto em um conjunto de medida de Lebesgue nula, ou seja, se seu comprimento for zero ($\int_{a}^{a}f(t) dt = 0$). Ainda sob **(b)**, se $f$ é uma função de densidade podemos definir $F(x) = \int_{-\infty}^{x} f(t) dt$ e $F$ verifica:

1. $x \le y \Rightarrow F(x) \le F(y)$;
2. Se $x_{n} \downarrow x \Rightarrow F(x_{n}) \downarrow F(x)$;
3. Se $x_{n} \downarrow -\infty \Rightarrow F(x_{n}) \downarrow 0$ e se $x_{n}\uparrow \infty \Rightarrow F(x_{n}) \uparrow 1$.

Dada uma variável aleatória com distribuição $F_{X}$, $X$ tem densidade se:

(i) $F_{X}$ é contínua;
(ii) $F_{X}$ é derivável por partes (ou derivável no interior de um número finito ou enumerável de intervalos fechados cuja união é igual a $\mathbb{R}$), ou derivável para todo $x$ exceto um número finito (enumerável) de pontos.

::: {.example}

\pgfplotsset{
  graf2/.style={
    xlabel=$x$,
    ylabel=$P(X \le x)$,
    width=7cm, height=7cm,
    ymin=-0.1,
    ymax=1.2
  }
}

\begin{center}
\begin{tikzpicture}[domain=0:1.1]
    \begin{axis}[
        graf2,
        grid = major,
        ytick distance=0.25,
        xtick distance=0.25]
        \addplot[draw=none] {0};
        \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
        \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
        \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
        \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 1, 1) node[above left] {$F_{X}(x)$};
        \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 1.5,1);
    \end{axis}
    \node [shape=rectangle, align=center](equation1) at (-5,2.5) {$F_{X}(x) = \begin{cases} 0, & x<0 \\ x, & x \in [0,1] \\ 1, & x > 1 \end{cases}$};
\end{tikzpicture}
\end{center}

Notas:

- $F_{X}$ é contínua;
- $\{0,1\}$ são pontos sem derivada;
- Podemos definir os seguintes intervalos em que $F_{X}$ é derivável: $(-\infty,0),(0,1),(1,\infty)$;
- $F_{X}'(x) = \begin{cases}1, & x \in (0,1) = f_{X}(x) \\ 0 , & c.c.\end{cases}$;
- $f(0)$ e $f(1)$ podem ser definidos como zero ou um, já que tais definições não alteram $F_{X}(x) = \int_{-\infty}^{x}f(t)dt$.

Em contrapartida, considere:

\begin{center}
\begin{tikzpicture}[domain=0:1.1]
    \begin{axis}[
        graf2,
        grid = major,
        ytick distance=0.25,
        xtick distance=0.25]
        \addplot[draw=none] {0};
        \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
        \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
        \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
        \draw[very thick, black] (axis cs: 0, 1) -- (axis cs: 1, 1) node[above left] {$F_{X}(x)$};
        \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 1.5,1);
        \node[circle,fill=black,scale=0.4] (PA) at (axis cs: 0,1) {};
        \node[circle,fill=white,scale=0.4,draw] (P0) at (axis cs: 0,0) {};
    \end{axis}
    \node [shape=rectangle, align=center](equation1) at (-5,2.5) {$F_{X}(x) = \begin{cases} 0, & x<0 \\ 1, & x \ge 0 \end{cases}$};
\end{tikzpicture}
\end{center}

Notas:

- $F_{X}$ não é contínua;
- $P(X=0) = \lim_{x \to 0^{+}}F_{X}(x) - \lim_{x \to 0^{-}}F_{X}(x) = 1$.

:::

::: {.example}

Considere a densidade triangular:

\pgfplotsset{
  graf3/.style={
    xlabel=$x$,
    width=10cm, height=6cm,
    ymin=-0.1,
    ymax=1.5
  }
}

\begin{center}
\begin{tikzpicture}[domain=0:2.5]
  \begin{axis}[graf3, grid=major]
  \addplot[draw=none] {0};
  \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
  \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
  \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
  \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 1, 1);
  \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 2, 0) node[above right] {$f_{X}(x)$};
  \draw[very thick, black] (axis cs: 2, 0) -- (axis cs: 3, 0);
  \end{axis}
  \node [shape=rectangle, align=center](equation1) at (-3.5,2.5) {$f_{X}(x) = \begin{cases} x, & \text{se } 0 \le x < 1 \\ 2-x, & \text{se } 1 \le x < 2 \\ 0 & c.c. \end{cases}$};
\end{tikzpicture}
\end{center}

Por definição, $f(x) \ge 0 \; \forall x$. Para verificarmos que a probabilidade total é igual a um, podemos realizar a seguinte integração por partes:

\begin{align*}
\int_{-\infty}^{x}f_{X}(x)\mathrm{d}x &= \int_{0}^{2}f_{X}(x)\mathrm{d}x \\
&= \int_{0}^{1}x \mathrm{d}x + \int_{1}^{2}(2-x)\mathrm{d}x \\
&= \frac{x^{2}}{2}\Big{|}_{0}^{1} + 2x \Big{|}_{1}^{2} - \frac{x^{2}}{2} \Big{|}_{1}^{2} \\
&= 1
\end{align*}

O que demonstra que $f_{X}(x)$ é densidade de probabilidade.

:::

::: {.conjecture}

Cada função de distribuição se corresponde com apenas uma distribuição? Não.

:::

::: {.proof}

Considere, por exemplo, que a variável aleatória $X \sim N(0,1)$. Logo, a sua função distribuição de probabilidade é dada por $f_{X}(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}$ e $\Phi(x)$ é sua acumulada. Vejamos que $X \sim N(0,1) \Longleftrightarrow -X \sim N(0,1)$:

Seja $\omega$ um possível valor de $-X$, devemos calcular $P(-X \le \omega)$ e provar que $P(-X \le \omega) = \Phi(\omega)$:

\begin{equation*}
P(-X \le \omega) = P(X \ge -\omega) = 1 - P(X \le \omega) = 1 - \Phi(-\omega) = 1 - (1 - \Phi(\omega)) = \Phi(\omega)
\end{equation*}

:::

## Variáveis aleatórias e $\sigma$-álgebra de Borel

Se $X$ é uma variável aleatória em $(\Omega, \mathcal{A}, P)$, cada evento $[X \le x] \in \mathcal{A} \; \forall x \in \mathbb{R}$. Isto é, $[X \in \mathcal{B}]$, onde $[X \in \mathcal{B}] = [X \le x]$ é um evento e $P(X \in \mathcal{B})$ é bem definido. No entanto, a operacionalidade do sistema $(\Omega, \mathcal{A},P)$ pode ser estendido a todo boreliano (ou seja, a todos os elementos da $\sigma$-álgebra de Borel, que é a menor $\sigma$-álgebra contendo os intervalos cujos comprimentos estejam bem definidos).

::: {.proposition}

Se $X$ é uma variável aleatória em $(\Omega,\mathcal{A},P)$, então o evento $[x \in \mathcal{B}] = \{\omega : \omega \in \Omega \text{ e } X(\omega) \in \mathcal{B}\}$ é um evento aleatório para todo $\mathcal{B}$ boreliano (ou seja, $[x \in B] \in \mathcal{A} \; \forall B \in \mathcal{B}$).

:::

Podemos ver que diferentes tipos de intervalos (leia-se borelianos) podem ser mostrados como pertencentes à $\sigma$-álgebra, de modo que variáveis aleatórias que operam sobre esses intervalos estarão bem definidas:

1. Se $B = (-\infty, b] \Rightarrow [X \in B] \in \mathcal{A}$ de acordo com a definição de variável aleatória;
2. Se $B = (a, \infty)$, podemos fazer $B = (-\infty, a]^{c}$. Como o evento $[X \le a] \in \mathcal{A}$ por definição, sendo $\mathcal{A}$ uma $\sigma$-álgebra, deve ocorrer que $[X \le a]^{c} = B \in \mathcal{A}$, ou seja, $B \in \mathcal{A}$;
3. Se $B = (a, b] \Rightarrow [X \in B] = [X \in (a,b]] = [X \le b] - [X \le a]$. Como $[X \le b] \in \mathcal{A}$ e $[X \le a] \in \mathcal{A}$, então $P(X \in B) = P(X \le b) - P(x \le a) = F_{X}(b) - F_{X}(a)$;
4. Se $B = (a,b) \Rightarrow B = \bigcup_{n=1}^{\infty}\left(a,b-\frac{1}{n}\right]$ Sabemos que os eventos $\left(a < X \le b - \frac{1}{n}\right] \in \mathcal{A}$ e as suas uniões também pertencem à $\mathcal{A}$. Quanto à probabilidade, temos $P(X \in B) = P\left(\bigcup_{n=1}^{\infty}\left(a < X \le b - \frac{1}{n}\right]\right) = \lim_{n \to \infty}P\left(\left(a < X \le b - \frac{1}{n}\right]\right) = \lim_{n \to \infty}F_{X}\left(b - \frac{1}{n}\right) - F_{X}(a) = F_{X}(b^{-}) - F_{X}(a)$;
5. Se $B = \bigcup_{i = 1}^{n}B_{i}:B_{i} \in \mathcal{A}\; \forall i$, e sendo os $B_{i}$'s disjuntos, temos que $[X \in B] = \bigcup_{i=1}^{n}[X \in B_{i}] \Rightarrow P([X \in B]) = \sum_{i=1}^{n}P(X \in B_{i})$.

Podemos assim reformular os axiomas de Kolmogorov:

- $Ax_{1}(K)$: $P_{X}(B) = P(X \in B) \ge 0$;
- $Ax_{2}(K)$: $P_{X}(\mathbb{R}) = P(X \in \mathbb{R}) = 1$;
- $Ax_{3}(K)$: Se $B_{1}, \ldots, B_{n} \in \mathcal{B}$, com $B_{i} \cap B_{j} = \emptyset \; \forall i \neq j \Rightarrow P_{X}(\bigcup B_{n}) = P(X \in \bigcup_{n}B_{n}) = P(\bigcup_{n}[X \in B_{n}]) = \sum_{n}P(X \in B_{n})$.

::: {.definition}

A probabilidade $P_{X}$ definida na $\sigma$-álgebra de Borel por $P_{X}(B) = P(X \in B)$ é a distribuição de $X$.

:::

::: {.proposition}

a) Se $X$ é uma variável aleatória discreta com valores em $\{x_{1},x_{2},\ldots\} \Rightarrow P_{X}(B) = \sum_{i:x_{i} \in B}P(x_{i})$;
b) Se $X$ é absolutamente contínua com densidade $f \Rightarrow P_{X}(B) = \int_{B}f_{X}dx$.

:::

## Variáveis contínuas

::: {.proposition}

Se $X \sim f_{X}, \; y = bx+c, \; b>0$ e $c \in \mathbb{R} \Rightarrow Y \sim f_{Y}$ onde $f_{Y}(y) = \frac{1}{b}f_{X}(\frac{y-c}{b}); y \in \mathbb{R}$, onde $c$ é dito um parâmetro de posição (muitas vezes de posição central) e $b$ um parâmetro de escala.

:::

### Exemplos

::: {.example name="Distribuição Normal"}

\begin{equation*}
f(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}} \Longrightarrow f_{\mu,\sigma}(x) = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}
\end{equation*}

Aqui, $\mu$ representa a média (posição central) da distribuição e $\sigma^{2}$ a sua variância.

:::

::: {.example name="Distribuição Cauchy"}

\begin{equation*}
f(x) = \frac{1}{\pi(1 + x^{2})} \Longrightarrow f_{b,M}(x) = \frac{1}{b}\frac{1}{\pi\left(1+\left(\frac{x-M}{b}\right)^{2}\right)} = \frac{b}{\pi(b^{2}+(x-M)^2)}
\end{equation*}

Neste caso, $M$ é a mediana da distribuição e $b$ representa a distância entre $M$ e o 1º quartil da distribuição.

:::

::: {.example name="Distribuições Exponencial e Gamma"}

Considere $g(x) = e^{-x} I_{0,\infty}(x)$. Sabemos que $g$ é uma distribuição de probabilidade pois:

\begin{equation*}
\begin{cases*}
g(x) \ge 0 \;\forall x \in (0,\infty) \\
\int_{0}^{\infty}e^{-x}dx = 1
\end{cases*}
\end{equation*}

Vamos agora incluir no formato do tipo exponencial um componente polinomial. Dado $\alpha > 0$, defina $g(x) = x^{\alpha - 1}e^{-x}$. Podemos ver que $g$ é integrável, de modo que:

\begin{align*}
\int_{0}^{\infty}g(x)dx &= \int_{0}^{\infty}x^{\alpha - 1}e^{-x}dx = \Gamma(\alpha) \\
f_{X}(x) &= \begin{cases}\frac{1}{\Gamma(\alpha)}x^{\alpha - 1}e^{-x} & x>0 \\ 0 & c.c.\end{cases}
\end{align*}

Defina agora $y = \frac{X}{\beta}$ onde $X \sim \text{Gamma}(\alpha,1)$ e $\beta > 0$. A densidade de $Y$ pode ser encontrada por meio de:

\begin{align*}
P(Y \le y) &= P\left(\frac{X}{\beta} \le y\right) = P(X \le \beta y) \Rightarrow F_{Y}(y) = F_{X}(\beta y) \\
f_{Y}(y) &= \beta f_{X}(\beta y) = \beta\frac{(\beta y)^{\alpha - 1}}{\Gamma(\alpha)}e^{-\beta y} = \frac{\beta^{\alpha}}{\Gamma(\alpha)}y^{\alpha - 1}e^{-\beta y}
\end{align*}

Nesse caso (conhecido como distribuição Gama) $\frac{1}{\beta}$ é um parâmetro de escala e $\alpha$ é um parâmetro de forma. Temos alguns casos especiais, como:

- Se $\alpha = 1\; : Y \sim \text{Exp}(\beta)$;
- Se $\alpha = \frac{n}{2}$, com $n$ inteiro e $\beta = \frac{1}{2} \;: Y \sim \chi^{2}(n)$

:::

## Variáveis aleatórias multidimensionais

::: {.definition}

A distribuição de probabilidades do vetor aleatório dado por $(x_{1},\ldots,x_{n})$ é uma tabela que associa a cada valor $(x_{1},\ldots,x_{n})$ sua probabilidade $P(x_{1},\ldots,x_{n}) = P(X_{1} = x_{1}, \ldots,X_{n}=x_{n})$, onde $p$ é a distribuição conjunta.

:::

::: {.example}

Considere o conjunto de 32 cartas para poker: 7,8,9,10,J,Q,K,A, dos 4 naipes. Duas cartas são retiradas aleatoriamente, sem reposição, e $X =$ número de ases que a pessoa recebe e $Y =$ número de cartas de copas que a pessoa recebe. Qual a probabilidade $P(X=0,Y=0)$?

\begin{equation*}
P(X=0,Y=0) = \frac{\binom{21}{2}}{\binom{32}{2}} = \frac{210}{496}
\end{equation*}

:::

::: {.definition}

A função de distribuição acumulada do par de variáve aleatórias $(X,Y)$ é dada por:

\begin{equation*}
F(X,Y) = P(X \le x, Y \le y) = \sum_{\{i:x_{i} \le x\}}\sum_{\{j: y_{j} \le y\}}P(X = x_{i}, Y = y_{i})
\end{equation*}

:::

Seja $\underbar{X} = (X_{1}, \ldots, X_{n})$ tal que $X_{i}$ é variável aleatória definida em $(\Omega, \mathcal{A}, P) \; \forall i$. Então $F$, a acumulada de $\underbar{X}$ verifica:

- **$F_{1}$**: $F$ é não decrescente em cada uma das coordenadas;
- **$F_{2}$**: $F$ é contínua à direita em cada uma das coordenadas;
- **$F_{3}$**: $\lim_{x_{i} \to -\infty}F(x_{1}, \ldots, x_{n}) = 0$ e $\lim_{x_{i} \to \infty \forall i}F(x_{1}, \ldots, x_{n}) = 1$.

As provas de $F_{1}$ e $F_{2}$ são de simples construção. Para $F_{3}$ temos:

::: {.proof}

Considere $i$ fixo e o evento $[X_{1} \le x_{1}, \ldots, X_{i-1} \le x_{i-1}, X_{i} \le -m, X_{i+1} \le x_{i+1}, \ldots, X_{n} \le x_{n}]$. Logo, $F(x_{1},\ldots,x_{i-1},-m,x_{i+1},\ldots,x_{n}) \xrightarrow[m \to \infty]{} 0$.

Por outro lado, note que $[X_{1} \le x_{1}, \ldots, X_{i-1} \le x_{i-1}, X_{i} \le m, X_{i+1} \le x_{i+1}, \ldots, X_{n} \le x_{n}] \xrightarrow[m \to \infty]{} [X_{1} \le x_{1}, \ldots, X_{i-1} \le x_{i-1}, X_{i+1} \le x_{i+1}, \ldots, X_{n} \le x_{n}]$ (que é o evento marginal sem o $X_{i}$). Já se $x_{i} \to \infty \; \forall i : \bigcap_{i=1}^{n}[X_{i} \le x_{i}] \uparrow \Omega \Rightarrow F(x_{1}, \ldots, x_{n}) = P\left(\bigcap_{i=1}^{n}[X_{i} \le x_{i}]\right) \uparrow 1, x_{i} \to \infty \; \forall i$.

:::

$F_{1},F_{2}$ e $F_{3}$ não são condições suficientes para que $F$ seja uma função de distribuição acumulada. Vejamos um exemplo que segue $F_{1},F_{2}$ e $F_{3}$ e que não é função de distribuição acumulada:

Seja $F_{0}(x,y) = \begin{cases}1 & \text{se }x \ge 0, y \ge 0, x + y \ge 1 \\ 0 & \text{c.c.} \end{cases}$. Graficamente, temos:

\pgfplotsset{
  graf4/.style={
    xlabel=$x$,
    ylabel=$y$,
    width=7cm, height=7cm,
    ymin=-0.1,
    ymax=1.3
  }
}

\begin{center}
\begin{tikzpicture}[domain=0:1.1]
    \begin{axis}[
        graf4,
        grid = major,
        ytick distance=0.5,
        xtick distance=0.5]
        \addplot[draw=none] {0};
        \draw[very thick, black] (axis cs: 0, 1) -- (axis cs: 1, 0);
        \draw[very thick, black] (axis cs: 0, 1) -- (axis cs: 0, 3);
        \draw[very thick, black] (axis cs: 1, 0) -- (axis cs: 3,0);
        \draw[thin, black] (axis cs: 0, 0) -- (axis cs: 0, 1);
        \draw[thin, black] (axis cs: 0, 0) -- (axis cs: 1, 0);
        \fill[fill=black!40!white, opacity=0.5] (axis cs: 0, 5) -- (axis cs: 0, 1) -- (axis cs: 1, 0) -- (axis cs: 5, 0);
        \fill[fill=black!20!white, opacity=0.5] (axis cs: 0, 0) -- (axis cs: 0, 1) -- (axis cs: 1, 0);
        \node at (axis cs: 0.25, 0.25) {$F(x,y) = 0$};
        \node at (axis cs: 0.75, 0.75) {$F(x,y) = 1$};
    \end{axis}
\end{tikzpicture}
\end{center}

É fácil ver que $F_{0}$ segue $F_{1}, F_{2}$ e $F_{3}$, mas vejamos que $F_{0}$ atribui probabilidade negativa a certos eventos, a ver $[0 \le X \le 1, 0 \le Y \le 1]$:

\begin{align*}
F_{0}(0,0) &= P(X \le 0, Y \le 0) \\
F_{0}(1,1) &= P(X \le 1, Y \le 1) \\
F_{0}(1,1) - F_{0}(1,0) &= P(X \le 1, Y \le 1) - P(X \le 1, Y \le 0) = P(X \le 1, 0 \le Y \le 1)\\
F_{0}(0,1) - F_{0}(0,0) &= P(X \le 0, Y \le 1) - P(X \le 0, Y \le 0) = P(X \le 0, 0 \le Y \le 1)\\
F_{0}(1,1) - F_{0}(1,0) - F_{0}(0,1) - F_{0}(0,0) &= P(X \le 1, 0 \le Y \le 1) - P(X \le 0, 0 \le Y \le 1) \\
&= P(0 \le X \le 1, 0 \le Y \le 1) = -1
\end{align*}

Defina $\Delta_{k,I}(g(x_{1},\ldots,x_{k})) = g(x_{1}, \ldots, x_{k-1},b) - g(x_{1}, \ldots, x_{k-1},a)$ onde $g:\mathbb{R}^{k} \to \mathbb{R}; I = (a,b], a \le b$. Logo, se $I_{1} = (a_{1},b_{1}]$ e $I_{2} = (a_{2},b_{2}], F:\mathbb{R}^{2} \to \mathbb{R}$. Então:

\begin{align*}
\Delta_{1,I_{1}}(\Delta_{2,I_{2}}(F(x,y))) &= \Delta_{1,I_{1}}(F(x, b_{2}) - F(x, a_{2})) \\
&= F(b_{1}, b_{2}) + F(a_{1}, a_{2}) - F(a_{1}, b_{2}) - F(b_{1}, a_{2}) \ge 0 \\
&= P(a_{1} < X \le b_{1}, a_{2} < Y \le b_{2}) \ge 0
\end{align*}

No geral:

- $F_{4}$: $\Delta_{1,I_{1}}\Delta_{2,I_{2}}\ldots\Delta_{n,I_{n}}(F(x_{1},\ldots,x_{n})) \ge 0 \; \forall I_{k} = (a_{k}, b_{k}]; a_{k} \le b_{k}, k=1,\ldots,n$.

::: {.definition}

Seja $F:\mathbb{R}^{n} \to \mathbb{R}$ seguindo $F_{1}, F_{2}, F_{3}$ e $F_{4}$, logo $F$ é uma função de distribuição acumulada n-dimensional (ou n-variada).

- **a)** Se o vetor aleatório $(X_{1},\ldots,X_{n})$ toma valores em um conjunto discreto, o vetor é discreto;
- **b)** Se para o vetor aleatório $(X_{1},\ldots,X_{n})$, $F$ é dada pela forma $F(x_{1}, \ldots, x_{n}) = \int_{-\infty}^{x_{n}} \ldots \int_{-\infty}^{x_{1}}f(t_{1}, \ldots, t_{n}) dt_{n} \ldots dt_{1}, \\ \forall (x_{1},\ldots, x_{n})$ onde $f(t_{1}, \ldots, t_{n}) \ge 0 \; \forall (t_{1},\ldots,t_{n}) \in \mathbb{R}^{n}$ então $(X_{1},\ldots,X_{n})$ é um vetor absolutamente contínuo com densidade $f$ (densidade conjunta).

:::

::: {.definition}

A probabilidade definida em $\mathcal{B}^{n}$ (borelianos em $\mathbb{R}^{n}$) por $P(\underbar{X} \in B)$ (com $B \in \mathcal{B}^{n}$) é chamada de distribuição conjunta de $\underbar{X} = (X_{1},\ldots,X_{n})$, com notação: $P_{\underbar{X}}(B) = P(\underbar{X} \in B)$.

:::

::: {.proposition}

- **a)** Se o vetor aleatório $\underbar{X}$ é discreto, $P_{\underbar{X}}(B) = \sum_{\{i:x_{i} \in B\}}P(X_{i} = x_{i}) \; \forall B \in \mathcal{B}^{n}$;
- **b)** Se $\underbar{X}$ é absolutamente contínuo com densidade $f$, $P_{\underbar{X}}(B) = P(\underbar{X} \in B) = \int \ldots \int_{B} f(x_{1}, \ldots, x_{n}) dx_{n} \ldots dx_{1}$.

:::

## Independência

::: {.definition}

As variáveis aleatórias são (coletivamente) independentes se:

\begin{equation*}
P(X_{1} \in B_{1}, \ldots, X_{n} \in B_{n}) = \prod_{i=1}^{n}P(X_{i} \in B_{i}), \; \forall B_{i} \in \mathcal{B}^{n}, \forall i = 1, \ldots, n
\end{equation*}

:::

Se $X_{1},\ldots,X_{n}$ são coletivamente independentes, então $X_{i1},\ldots,X_{ik}$ são coletivamente independentes $\forall k$.

### Critérios ou consequências

::: {.proposition #propacumulada}

- **a)** Se $X_{1},\ldots,X_{n}$ são independentes, então $F_{X_{1} \ldots X_{n}}(x_{1},\ldots,x_{n}) = \prod_{i=1}^{n}F_{X_{i}}(x_{i}),\forall (x_{1},\ldots,x_{n}) \in \mathbb{R}^{n}$;
- **b)** Se existem funções $F_{1},\ldots,F_{n}$ tais que $\lim_{n \to \infty}F_{i}(x) = 1, \forall i$ e $F_{X_{1},\ldots,X_{n}}(x_{1},\ldots,x_{n}) = \prod_{i=1}^{n}F_{i}(x_{i}), \forall (x_{1},\ldots,x_{n}) \in \mathbb{R}^{n} \Rightarrow X_{1},\ldots, X_{n}$ são independentes e $F_{i} = F_{X_{i}}, \forall i$.

:::

::: {.proof}

- **a)** Se $X_{1},\ldots,X_{n}$ são coletivamente independentes e tomamos $[X_{i} \le x_{i}] = (-\infty, x_{i}] = B_{i}$. Então:

\begin{align*}
F_{X_{1} \ldots X_{n}}(x_{1},\ldots,x_{n}) &= P(X_{1} \le x_{1}, \ldots, X_{n} \le x_{n}) \\
&= P(X_{1} \in B_{1},\ldots, X_{n} \in B_{n}) \\
&\stackrel{Ind}{=} \prod_{i=1}^{n}P(X_{i} \in B_{i}) \\
&= \prod_{i=1}^{n}P(X_{i} \le x_{i}) = \prod_{i=1}^{n}F_{X_{i}}(x_{i}) \; \forall (x_{1},\ldots,x_{n})
\end{align*}

- **b)** Para cada $i$, $F_{X_{i}}(x_{i}) = P(X_{i} \le x_{i}) = \lim_{m \to \infty}P(X_{1} \le m, \ldots, X_{i-1} \le m, X_{i} \le x_{i}, X_{i+1} \le m, \ldots, X_{n} \le m)$, de modo que:

\begin{align*}
F_{X_{i}}(x_{i}) &= \lim_{m \to \infty}F_{X_{1}\ldots X_{n}}(m,\ldots,m,x_{i},m,\ldots,m) \\
&\stackrel{Hip}{=} \lim_{m \to \infty}\left(\prod_{j=1}^{i-1}F_{j}(m) \times F_{i}(x_{i}) \times \prod_{j=i+1}^{n}F_{j}(m)\right) \\
&= F_{i}(x_i)
\end{align*}

Logo, a marginal de $X_{i}$ é precisamente $F_{i}, \forall i$. Devemos ainda verificar que $P(X_{1} \in B_{1}, \ldots, X_{n} \in B_{n}) = \prod_{i=1}^{n}P(X_{i} \in B_{i}) \; \forall B_{i} \in \mathcal{B}^{n}$. Considere $B_{i} = (a_{i},b_{i}], a_{i} \le b_{i}, a_{i}, b_{i} \in \mathbb{R}$. Temos que:

\begin{align*}
P(X_{1} \in B_{1}, \ldots, X_{n} \in B_{n}) &= P(a_{1} < X_{1} \le b_{1}, \ldots, a_{n} < X_{n} \le b_{n}) \\
&= \Delta_{1,I_{1}} \ldots \Delta_{n,I_{n}}\left(F_{X_{1} \ldots X_{n}}(x_{1},\ldots,x_{n})\right) \\
&\stackrel{Ind}{=} \Delta_{1,I_{1}} \ldots \Delta_{n,I_{n}}(F_{X_{1}}(x_{1})\ldots F_{X_{n}}(x_{n})) \\
&= [F_{X_{1}}(b_{1}) - F_{X_{1}}(a_{1})] \times \ldots \times [F_{X_{n}}(b_{n}) - F_{X_{n}}(a_{n})] \\
&= \prod_{i=1}^{n}P(a_{i} < X_{i} \le b_{i}) = \prod_{i=1}^{n}P(X_{i} \in B_{i})
\end{align*}

:::

### Caso contínuo

::: {.proposition}

- **a)** Se $X_{1},\ldots,X_{n}$ são independentes e possuem densidades $f_{X_{1}}, \ldots, f_{X_{n}}$, respectivamente, então $f_{X_{1}\ldots X_{n}}(x_{1},\ldots,x_{n}) = \prod_{i=1}^{n}f_{X_{i}}(x_{i}) \; \forall (x_{1},\ldots,x_{n}) \in \mathbb{R}^{n}$ é a densidade conjunta de $X_{1},\ldots,X_{n}$;
- **b)** Se $X_{1},\ldots,X_{n}$ tem densidade conjunta $f_{X_{1}\ldots X_{n}}(x_{1},\ldots,x_{n}) : f_{X_{1}\ldots X_{n}}(x_{1},\ldots,x_{n}) = \prod_{i=1}^{n}f_{i}(x_{i}) \; \forall (x_{1},\ldots,x_{n}) \in \mathbb{R}^{n}$, onde $f_{i}(x) \ge 0 \; \forall x : \int_{-\infty}^{\infty}f_{i}(x)dx = 1 \; \forall i$, então $X_{1},\ldots,X_{n}$ são independentes e $f_{i}$ é a densidade marginal de $X_{i} \; \forall i$.

:::

::: {.proof}

- **a)** Como consequência da proposição \@ref(prp:propacumulada), temos que: $F_{X_{1}\ldots X_{n}}(x_{1},\ldots,x_{n}) = \prod_{i=1}^{n}F_{X_{i}}(x_{i}), \forall (x_{1},\ldots,x_{n})$. Logo, por definição temos:

\begin{equation*}
\prod_{i=1}^{n}F_{X_{i}}(x_{i}) = \prod_{i=1}^{n}\int_{-\infty}^{x_{i}}f_{X_{i}}(t)dt = \int_{-\infty}^{x_{1}}\dots\int_{-\infty}^{x_{n}}f_{X_{1}}(t_{1})\ldots f_{X_{n}}(t_{n}) dt_{n} \ldots dt_{1}
\end{equation*}

Assim, $f_{X_{1}},\ldots,f_{X_{n}}$ é a densidade conjunta.

- **b)** Considere:

\begin{align*}
F_{X_{1}\ldots X_{n}}(x_{1},\ldots,x_{n}) &= \int_{-\infty}^{x_{1}} \dots \int_{-\infty}^{x_{n}}f_{X_{1}\ldots X_{n}}(t_{1},\ldots,t_{n})dt_{n}\ldots dt_{1} \\
&= \int_{-\infty}^{x_{1}} \dots \int_{-\infty}^{x_{n}}f_{1}(t_{1}) \ldots f_{n}(t_{n}) dt_{n} \ldots dt_{1} \\
&= \prod_{i=1}^{n}\int_{-\infty}^{x_{i}}f_{i}(t_{i})dt_{i}
\end{align*}

Defina $F_{i}(x) = \int_{-\infty}^{x_{i}}f_{i}(t)dt$. Sendo assim:

\begin{equation*}
\prod_{i=1}^{n} \int_{-\infty}^{x_{i}}f_{i}(t_{i})dt_{i} = \prod_{i=1}^{n}F_{i}(x_{i})
\end{equation*}

Note que, pela hipótese nas $f_{i}$'s, as $F_{i}$'s são acumuladas em particular, e $F_{i}(x) \to 1, x \to \infty$, e pela proposição \@ref(prp:propacumulada): $F_{i}(x) = F_{X_{i}}(x_{i})$, logo $f_{X_{i}} = f_{i}$.

:::

### Propriedades

- **a)** Se $F(x,y)$ é a função de distribuição acumulada conjunta de $(X,Y)$, então $F_{X}(x) = \lim_{y \to \infty}F(x,y) = F(x,\infty)$ é a função de distribuição acumulada marginal de $X$;
- **b)** Se $f(x,y)$ é a função de densidade conjunta de $(X,Y)$, então $f_{X}(x) = \int_{-\infty}^{\infty}f(x,y)dy$ é a densidade marginal de $X$.

::: {.example}

\begin{equation*}
f_{XY}(x,y) = \frac{1}{2\pi \sigma_{1}\sigma_{2}\sqrt{1-\rho^{2}}}\exp\left\{-\frac{1}{2(1-\rho^{2})}\left[\left(\frac{x-\mu_{1}}{\sigma_{1}}\right)^{2} + \left(\frac{y-\mu_{2}}{\sigma_{2}}\right)^{2} - 2\rho \left(\frac{x-\mu_{1}}{\sigma_{1}}\right)\left(\frac{y-\mu_{2}}{\sigma_{2}}\right)\right]\right\}
\end{equation*}

Sendo $\sigma_{i} > 0, i = 1,2; -1 < \rho < 1; \mu_{i} \in \mathbb{R}, i = 1,2$. Logo, $(X,Y) \sim N_{2}\left(\binom{\mu_{1}}{\mu_{2}},\begin{bmatrix}\sigma_{1} & \rho \\ \rho & \sigma_{2}\end{bmatrix}\right)$, onde, caso $\rho = 0, X$ e $Y$ são independentes.

:::

## Distribuições de funções de vetores

Seja $\underbar{X} = (X_{1},\ldots,X_{n})$ um vetor aleatório em $(\Omega, \mathcal{A},P)$. Seja $Y = g(X_{1},\ldots,X_{n})$. Qual a distribuição de $Y$?

- **Nota 1**: Para que $Y$ seja variável aleatória cada $B \in \mathcal{B}$ é necessário que $g^{-1}(B)$ seja mensurável, ou seja:

\begin{align*}
g^{-1}(B) &= \{x:g(x) \in B\} \\
&\Downarrow \\
F_{Y}(y) &= P(g(x) \le y)
\end{align*}

Generalizando, se $Y = g(X_{1},\ldots,X_{n})$:

\begin{equation*}
F_{Y}(y) = P(g(X_{1},\ldots,X_{n}) \le y) = P((X_{1},\ldots,X_{n}) \in B_{y}) = P_{\underbar{X}}(B_{y})
\end{equation*}

Onde $B_{y} = \{(x_{1},\ldots,x_{n}):g(x_{1},\ldots,x_{n}) \le y\}$.

- **Nota 2**: Se $\underbar{X}$ for discreto:

\begin{equation*}
P_{Y}(y_{j}) = \sum_{\{i:g(x_{i}) = y_{j}\}}P_{\underbar{X}}(x_{i})
\end{equation*}

::: {.example}

Sejam $X \sim U(0,1)$ e $Y = -\ln(x)$. Temos que $\forall x$ valor de $X:x \in (-\infty,0] \cup [1,\infty)$ o valor de $f_{X}(x) = 0$. Seja $x \in (0,1) \Leftrightarrow -\ln(x) \in (0,\infty)$, logo $\forall y$ valor de $Y:y \in (0,\infty)$. Calculemos $F_{Y}(y) = P(Y \le y)$:

\begin{align*}
F_{Y}(y) &= P(Y \le y) = P(-\ln(X) \le y) \\
&= P(\ln(X) \ge -y) \\
&= P(X \ge e^{-y}) \\
&= 1-P(X < e^{-y}) = 1-e^{-y}
\end{align*}

Assim, temos que $Y \sim Exp(1)$.

:::

::: {.example}

Sejam $X \perp Y; X \sim U(0,1); Y \sim U(0,1); Z = \frac{X}{Y}$. Determinar a distribuição de $Z$:

Os valores que geram indefinição de $Z$ são: $X=Y=0$ e $Y=0,X>0$, assim a boa definição de $Z$ é no espaço $[0 < X \le 1, 0 < Y \le 1]$. Vejamos se esse intervalo contém toda a massa de probabilidade:

\begin{equation*}
P([0 < X \le 1, 0 < Y \le 1]) = P(0 < X \le 1) \times P(0 < Y \le 1) = 1 \times 1 = 1
\end{equation*}

Logo, basta avaliar o conjunto $[0 < X \le 1, 0 < Y \le 1] \Rightarrow [Z \in (0, \infty)]$. Assim, calculemos $F_{Z}(z)$:

\begin{equation*}
F_{Z}(z) = P(Z \le z) = P\left(\frac{X}{Y} \le z\right) \Rightarrow \left[\frac{X}{Y} \le z\right] = \left[X \le zY\right] = \left[\frac{X}{z} \le Y\right]
\end{equation*}

Sabemos que $X$ e $Y$ pertencem ao intervalo $(0,1] \times (0,1]$, de modo que temos duas regiões genéricas para explorar: $z<1$ e $z>1$. De maneira gráfica, temos as seguintes regiões (considere $c > 1$):

\begin{center}
\begin{tikzpicture}[domain=0:1.2]
    \begin{axis}[
        graf4,
        grid = major,
        ytick distance=0.5,
        xtick distance=0.5]
        \addplot[draw=none] {0};
        \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 2, 2);
        \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 2, 1);
        \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 1, 2);
        \draw[thick, black] (axis cs: 0, 0) -- (axis cs: 2, 0);
        \draw[thick, black] (axis cs: 0, 0) -- (axis cs: 0, 2);
        \draw[thick, black] (axis cs: 1, 0) -- (axis cs: 1, 1);
        \draw[thick, black] (axis cs: 0, 1) -- (axis cs: 1, 1);
        \fill[fill=black!60!blue, opacity=0.5] (axis cs: 0, 0) -- (axis cs: 1, 1) -- (axis cs: 1, 0);
        \fill[fill=black!60!green, opacity=0.5] (axis cs: 0, 0) -- (axis cs: 1, 1) -- (axis cs: 0, 1);
        \node at (axis cs: 1, 1.15) {$y=x$};
        \node at (axis cs: 1.15, 0.4) {$y = \frac{x}{c}$};
        \node at (axis cs: 0.4, 1.15) {$y = cx$};
    \end{axis}
\end{tikzpicture}
\end{center}

Podemos ver que a região azul corresponde aos casos onde $z > 1$ e a região verde corresponde aos casos onde $z < 1$. Assim:

- $z<1$: \begin{equation*}F_{Z}(z) = \int_{0}^{z}\int_{0}^{\frac{x}{z}}dydx = \int_{0}^{z}y\big{|}_{0}^{\frac{x}{z}}dx = \int_{0}^{z}\frac{x}{z}dx = \frac{1}{z} \times \frac{x^{2}}{2}\bigg{|}_{0}^{z} = \frac{z^{2}}{2z} = \frac{z}{2}\end{equation*}
- $z>1$: \begin{equation*}F_{Z}(z) = 1 - \frac{1}{2z}\end{equation*}

De modo que a distribuição acumulada de $Z$ é dada por:

\begin{equation*}
F_{Z}(z) = \begin{cases}
0 & ,z \in (-\infty,0] \\
\frac{z}{2} & ,z \in (0,1) \\
1-\frac{1}{2z} & ,z \in [1,\infty)
\end{cases}
\end{equation*}

Assim, $F_{Z}(z) = P\left(\frac{X}{Y} \le z \right) = P((X,Y) \in B_{z})$, onde os conjuntos $B_{z}$ podem ter formatos diferentes dependendo de $z$. A densidade será dada pela derivada de $F_{Z}(z)$ com relação a $z$:

\begin{equation*}
f_{Z}(z) = \begin{cases}
0 & ,z \le 0 \\
\frac{1}{2} & ,z \in (0,1) \\
\frac{1}{2z^{2}} & ,z \ge 1
\end{cases}
\end{equation*}

:::

## Casos clássicos

### Soma

::: {.proposition #denssoma}

- **a)** Se $X$ e $Y$ tem densidade conjunta $f(x,y) \Rightarrow f_{X+Y}(z) = \int_{-\infty}^{\infty}f(z-t,t)dt = \int_{-\infty}^{\infty}f(t,z-t)dt$;
- **b)** Se $X \perp Y$ e $f_{X}$ e $f_{Y}$ são suas marginais, então $f_{X+Y}(z) = \int_{-\infty}^{\infty}f_{X}(z-t)f_{Y}(t)dt = \int_{-\infty}^{\infty}f_{X}(t)f_{Y}(z-t)dt$.

:::

::: {.proof}

Seja $Z = X+Y \Rightarrow [Z \le z] = [X+Y \le z] = [(x,y) \in B_{z}]$. Considerando $B_{z} = \{(x,y):x+y \le z\} = \{(x,y):x \le z-y\}$, temos que:

\begin{equation*}
F_{Z}(z) = \int\int_{B_{z}}f(x,y)dxdy = \int_{-\infty}^{\infty}\int_{-\infty}^{z-y}f(x,y)dxdy
\end{equation*}

Seja $y$ um valor fixo e defina $s=x+y, ds = dx$. Quando $x=z-y \Rightarrow s=z$, temos:

\begin{equation*}
F_{Z}(z) = \int_{-\infty}^{\infty}\int_{-\infty}^{z}f(s-y,y)dsdy = \int_{-\infty}^{z}\int_{-\infty}^{\infty}f(s-y,y)dyds = \int_{-\infty}^{z}g(s)ds
\end{equation*}

E $g$ é a densidade de $X+Y$, ou seja, $g(s) = f_{X+Y}(s)$.

:::

### Convolução

Se $f_{1}$ e $f_{2}$ são densidades de variáveis aleatórias, sua convolução $f_{1}*f_{2}$ é:

\begin{equation*}
f_{1}*f_{2}(x) = \int_{-\infty}^{\infty}f_{1}(x-t)f_{2}(t)dt
\end{equation*}

Assim, no caso da soma da proposição \@ref(prp:denssoma), podemos ver que:

\begin{equation*}
f_{X+Y}(z) = f_{X}*f_{Y}(z)
\end{equation*}
