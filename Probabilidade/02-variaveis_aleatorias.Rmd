---
title: "Notas de Aula - Capítulo 2"
subtitle: "Probabilidade"
author: "Caio Gomes Alves"
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{tikz}
   - \usepackage{pgfplots}
   - \usepackage{caption}
   - \usepackage{subcaption}
   - \usepackage{cancel}
   - \usepackage{mathtools}
   - \usepackage{annotate-equations}
output:
  bookdown::pdf_document2:
    toc: false
---


# Variáveis Aleatórias

## Variáveis aleatórias e funções de distribuição

::: {.example}

Considere um experimento em que uma moeda é lançada duas vezes. Seja $X =$ total de caras nos dois lançamentos. Denotemos o evento cara como $H$ e coroa como $T$. Logo:

\begin{center}
\begin{tabular}{|c|c|} \toprule
Espaço Amostral ($\Omega$) & $X$ \\ \midrule
HT & 1 \\
TH & 1 \\
HH & 2 \\
TT & 0 \\ \bottomrule
\end{tabular}
\end{center}

Logo, $X:\mathcal{F} \to \mathbb{R}$. Vale também que, $\forall x$ valor na imagem de $X$, $X^{-1}(x) \in \mathcal{F}$. Por exemplo:

\begin{align*}
x = 1 &\Rightarrow X^{-1}(1) = \{HT,TH\} \\
x = 2 &\Rightarrow X^{-1}(2) = \{HH\} \\
x = 0 &\Rightarrow X^{-1}(0) = \{TT\} \\
\end{align*}

:::

::: {.definition name="Variável aleatória"}

Seja $(\Omega,\mathcal{F},P)$ um espaço de probabilidades. Uma função $X:\mathcal{F} \to \mathbb{R}$ é variável aleatória se $[x \in I] \in \mathcal{F}, \; I \in \mathbb{R}$ (ou, equivalentemente, se $\{\omega:X(\omega) \in I\} \in \mathcal{F}; \; X^{-1}(I) \in \mathcal{F}$).

:::

::: {.definition name="Distribuição Acumulada"}

Considere um espaço de probabilidades $(\Omega,\mathcal{F},P)$ e $X:\mathcal{F} \to \mathbb{R}$ uma variável aleatória, defina $F(r) = P(X \le r) = P(\{\omega : X(\omega) \le r\})$.

:::

::: {.example}

Seja $X =$ número de caras em dois lançamentos de moeda (honesta). Temos que as probabilidades de $X$ são dadas por:

\begin{align*}
P(X = 0) &= P(\{TT\}) = \frac{1}{4} \\
P(X = 1) &= P(\{TH,HT\}) = \frac{2}{4} \\
P(X = 2) &= P(\{HH\}) = \frac{1}{4}
\end{align*}

Para encontrarmos a função de distribuição acumulada, podemos particinar o espaço e "acumular" as probabilidades. Para $r < 0$:

\begin{equation*}
F(r) = P([X \le r]) = P(\emptyset) = 0
\end{equation*}

Para $r \in [0,1)$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 0) = \frac{1}{4}
\end{equation*}

Para $r \in [1,2)$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 1) = P(X = 0) + P(X = 1) = \frac{3}{4}
\end{equation*}

Para $r \ge 2$:

\begin{equation*}
F(r) = P([X \le r]) = P(X \le 2) = P(X = 0) + P(X = 1) + P(X = 2) = 1
\end{equation*}

Logo, $F$ é dada por:

\begin{equation*}
F(r) = \begin{cases} 0, & r<0 \\ \frac{1}{4}, & r \in [0,1) \\ \frac{3}{4}, & r \in [1,2) \\ 1, & r \ge 2 \end{cases}
\end{equation*}

\pgfplotsset{
  graf1/.style={
    xlabel=$X$,
    width=10cm, height=7cm,
    mark=*,
    nodes near coords,
    point meta=explicit symbolic, % permite usar a 3 coluna como label.
    every node near coord/.append style={font=\footnotesize},
    nodes near coords align={vertical}
  }
}

\pgfplotstableread{
  i    x   px   PX   f  F
  1    0 0.25 0.25 1/4 1/4
  2    1 0.50 0.75 2/4 3/4
  3    2 0.25 1.00 1/4 4/4
}\distrprob

\begin{center}
\begin{tikzpicture}[domain=0:2]
    \begin{axis}[
      graf1,
      grid=major,
      ytick distance=0.25,
      ymin=-0.1,
      ymax=1.2,
      ylabel={$P(X \le r)$},
      title={Distribui\c{c}\~{a}o de probabilidades acumulada}]
      \addplot[thick, black, const plot, jump mark left]
      table[x=x, y=PX, meta=F] \distrprob;
      \draw[black] (axis cs: -1, 0) -- (axis cs: 0, 0);
      \draw[black] (axis cs: 2, 1) -- (axis cs: 3, 1);
    \end{axis}
\end{tikzpicture}
\end{center}

:::

::: {.theorem name="Propriedades da distribuição acumulada"}

Seja $X$ uma variável aleatória definida em $(\Omega,\mathcal{F},P)$, então a f.d.a. de $X$ ($F_{X}$ ou $F$) verifica:

a) $F$ é monótona não decrescente;
b) $F$ é contínua à direita;
c) $\lim_{t \to - \infty}F(t) = 0$ e $\lim_{t \to \infty}F(t) = 1$.

:::

::: {.proof}

a) Dados $a,b \in \mathbb{R} : a \le b; \; [X \le a] \subseteq [X \le b] \Rightarrow P([X \le a]) \le P([X \le b]) \Rightarrow F(a) \le F(b)$.

b) Se $X_{n}\downarrow x$, quando $n \to \infty$, temos que $\{[X \le x_{n}]\}_{n \ge 1}$ é tal que $\bigcap_{n \ge 1}[X \le x_{n}] = [X \le x]$. Isso significa que $[X \le x]$ acontece se e somente se $[X \le x_{n}] \; \forall n$. Além disso, $[X \le x_{n}] \downarrow [X \le x]$ quando $n \to \infty$, logo, pela continuidade da função de probabilidade $P([X \le x_{n}]) \downarrow P([X \le x]), n \to \infty$.

c) Considere agora que $x_{n} \downarrow -\infty \Rightarrow [X \le x_{n}] \downarrow \emptyset, \; n \to \infty \Rightarrow F(x_{n}) = P([X \le x_{n}]) \downarrow P(\emptyset) = 0, \; n \to \infty$.
Se $x_{n} \uparrow \infty \Rightarrow [X \le x_{n}] \uparrow \Omega, \; n \to \infty \Rightarrow F(x_{n}) = P([X \le x_{n}]) \uparrow P(\Omega) = 1, \; n \to \infty$.

:::

::: {.theorem}

Se $F$ é a f.d.a. da variável aleatória $X$, então:

a) Existem e são finitos os limites laterais $\lim_{t \to r^{-}}F(t), \lim_{t \to r^{+}}F(t), \forall r \in \mathbb{R}$ e $\lim_{t \to r^{-}}F(t) \le \lim_{t \to r^{+}}F(t)$;

b) $\lim_{t \to r^{+}}F(t) = F(r), \forall r \in \mathbb{R}$;

c) $F$ é descontínua em $r, r \in \mathbb{R}$ se e somente se $\lim_{t \to r^{-}}F(t) < F(r)$, com um salto de tamanho $F(r) - \lim_{t \to r^{-}}F(t)$;

d) $\forall r \in \mathbb{R}, P(X = r) = F(r) - \lim_{t \to r^{-}}F(t)$;

e) Existem no máximo um total enumerável de descontinuidades em $F$.

:::

::: {.proof}

a) $F$ é monótona e limitada ($0 \le F \le 1$). Logo, os limites laterais existem e são limitados.

b) Como $F$ é monótona não-decrescente, $\forall x,y : x \le y \Rightarrow F(x) \le F(y)$. Logo $\lim_{t \to r^{-}}F(t) \le \lim_{t \to r^{+}}F(t)$.

c) Como $F$ é monótona não-decrescente, uma descontinuidade só ocorre se e somente se $\lim_{t \to r^{-}}F(t) < \lim_{t \to r^{+}}F(t) = F(r)$.

d) Seja $r \in \mathbb{R}. \; [X \le r] = \bigcap_{n=1}^{\infty}(r-\frac{1}{n} < x \le r)$, logo:

\begin{align*}
P([X = r]) &= P\left(\bigcap_{n=1}^{\infty}\left(r-\frac{1}{n} < x \le r\right)\right) \\
&\Downarrow \text{(Teorema da continuidade)} \\
&=\lim_{n \to \infty}P\left(\left(r - \frac{1}{n} < x \le r\right)\right) \\
&= \lim_{n \to \infty} \left(F(r) - F\left(r - \frac{1}{n}\right)\right) \\
&= F(r) - \lim_{n \to \infty}F\left(r - \frac{1}{n}\right) \\
P([X = r]) &= F(r) - \lim_{t \to r^{-}}F(t)
\end{align*}

e) Seja $\mathcal{D}$ o conjunto de pontos de descontinuidades de $F$, e seja $\lim_{t \to x^{-}}F(t) = F(x^{-})$. Logo:

\begin{equation*}
\mathcal{D} = \{x \in \mathbb{R} : F(x) - F(x^{-}) > 0\}
\end{equation*}

Seja $\mathcal{D}_{n}$ o conjunto de pontos para os quais a amplitude do salto é maior ou igual a $\frac{1}{n}$. Logo:

\begin{equation*}
\mathcal{D}_{n} = \left\{x \in \mathbb{R}: F(x) - F(x^{-}) \ge \frac{1}{n}\right\} \Rightarrow \# D = |D| \le n
\end{equation*}

Se $x \in \mathcal{D} \Rightarrow \exists n_{0} > 1 : F(x) - F(x^{-}) \ge \frac{1}{n_{0}} \Rightarrow x \in \bigcup_{n=1}^{\infty}\mathcal{D}_{n}$. Se $x \in \bigcup_{n=1}^{\infty}\mathcal{D}_{n} \Rightarrow \exists n_{1} : x \in \mathcal{D}_{n} \Rightarrow x \in \mathcal{D}$. $\mathcal{D}$ portanto é a união enumerável de conjuntos finitos, logo é enumerável.

:::

## Natureza das variáveis aleatórias

a) $X$ é uma variável aleatória discreta se os valores que ela toma pertencem a um conjunto enumerável, logo $X:\Omega \to \{x_{1},x_{2},\ldots\}$ (ou seja, $X(\omega) \in \{x_{1},x_{2},\ldots\}, \forall \omega \in \Omega$) e $P: \{x_{1},x_{2},\ldots\} \to [0,1]$ é dado por $P(x_{i}) = P\{\omega : \omega \in \Omega \text{ e } X(\omega) = x_{i}\} \forall i \ge 1$.

b) $X$ é uma variável aleatória absolutamente contínua se $\exists f$ (uma função) tal que $f(x) \ge 0, \forall x \in \mathbb{R}$ e $F_{X}(x) = \int_{-\infty}^{x}f(t) dt$ (onde $f$ é chamada de densidade de $X$).

Sob **(a)** temos que $[X \le x] = \bigcup_{i : x_{i} \le x} [X = x_{i}]$. Logo $F_{x}(x) = \sum_{i : x_{i} \le x}P(x_{i})$.

Sob **(b)** estamos afirmando que $F_{X}$ é a integral de $f$ (ou seja, $f$ é a sua derivada) para todo $x$ exceto em um conjunto de medida de Lebesgue nula, ou seja, se seu comprimento for zero ($\int_{a}^{a}f(t) dt = 0$). Ainda sob **(b)**, se $f$ é uma função de densidade podemos definir $F(x) = \int_{-\infty}^{x} f(t) dt$ e $F$ verifica:

1. $x \le y \Rightarrow F(x) \le F(y)$;
2. Se $x_{n} \downarrow x \Rightarrow F(x_{n}) \downarrow F(x)$;
3. Se $x_{n} \downarrow -\infty \Rightarrow F(x_{n}) \downarrow 0$ e se $x_{n}\uparrow \infty \Rightarrow F(x_{n}) \uparrow 1$.

Dada uma variável aleatória com distribuição $F_{X}$, $X$ tem densidade se:

(i) $F_{X}$ é contínua;
(ii) $F_{X}$ é derivável por partes (ou derivável no interior de um número finito ou enumerável de intervalos fechados cuja união é igual a $\mathbb{R}$), ou derivável para todo $x$ exceto um número finito (enumerável) de pontos.

::: {.example}

\pgfplotsset{
  graf2/.style={
    xlabel=$x$,
    ylabel=$P(X \le x)$,
    width=7cm, height=7cm,
    ymin=-0.1,
    ymax=1.2
  }
}

\begin{center}
\begin{tikzpicture}[domain=0:1.1]
    \begin{axis}[
        graf2,
        grid = major,
        ytick distance=0.25,
        xtick distance=0.25]
        \addplot[draw=none] {0};
        \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
        \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
        \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
        \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 1, 1) node[above left] {$F_{X}(x)$};
        \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 1.5,1);
    \end{axis}
    \node [shape=rectangle, align=center](equation1) at (-5,2.5) {$F_{X}(x) = \begin{cases} 0, & x<0 \\ x, & x \in [0,1] \\ 1, & x > 1 \end{cases}$};
\end{tikzpicture}
\end{center}

Notas:

- $F_{X}$ é contínua;
- $\{0,1\}$ são pontos sem derivada;
- Podemos definir os seguintes intervalos em que $F_{X}$ é derivável: $(-\infty,0),(0,1),(1,\infty)$;
- $F_{X}'(x) = \begin{cases}1, & x \in (0,1) = f_{X}(x) \\ 0 , & c.c.\end{cases}$;
- $f(0)$ e $f(1)$ podem ser definidos como zero ou um, já que tais definições não alteram $F_{X}(x) = \int_{-\infty}^{x}f(t)dt$.

Em contrapartida, considere:

\begin{center}
\begin{tikzpicture}[domain=0:1.1]
    \begin{axis}[
        graf2,
        grid = major,
        ytick distance=0.25,
        xtick distance=0.25]
        \addplot[draw=none] {0};
        \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
        \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
        \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
        \draw[very thick, black] (axis cs: 0, 1) -- (axis cs: 1, 1) node[above left] {$F_{X}(x)$};
        \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 1.5,1);
        \node[circle,fill=black,scale=0.4] (PA) at (axis cs: 0,1) {};
        \node[circle,fill=white,scale=0.4,draw] (P0) at (axis cs: 0,0) {};
    \end{axis}
    \node [shape=rectangle, align=center](equation1) at (-5,2.5) {$F_{X}(x) = \begin{cases} 0, & x<0 \\ 1, & x \ge 0 \end{cases}$};
\end{tikzpicture}
\end{center}

Notas:

- $F_{X}$ não é contínua;
- $P(X=0) = \lim_{x \to 0^{+}}F_{X}(x) - \lim_{x \to 0^{-}}F_{X}(x) = 1$.

:::

::: {.example}

Considere a densidade triangular:

\pgfplotsset{
  graf3/.style={
    xlabel=$x$,
    width=10cm, height=6cm,
    ymin=-0.1,
    ymax=1.5
  }
}

\begin{center}
\begin{tikzpicture}[domain=0:2.5]
  \begin{axis}[graf3, grid=major]
  \addplot[draw=none] {0};
  \draw[black] (axis cs: -1, 0) -- (axis cs: 3, 0);
  \draw[black] (axis cs: 0, -1) -- (axis cs: 0, 3);
  \draw[very thick, black] (axis cs: -1, 0) -- (axis cs: 0, 0);
  \draw[very thick, black] (axis cs: 0, 0) -- (axis cs: 1, 1);
  \draw[very thick, black] (axis cs: 1, 1) -- (axis cs: 2, 0) node[above right] {$f_{X}(x)$};
  \draw[very thick, black] (axis cs: 2, 0) -- (axis cs: 3, 0);
  \end{axis}
  \node [shape=rectangle, align=center](equation1) at (-3.5,2.5) {$f_{X}(x) = \begin{cases} x, & \text{se } 0 \le x < 1 \\ 2-x, & \text{se } 1 \le x < 2 \\ 0 & c.c. \end{cases}$};
\end{tikzpicture}
\end{center}

Por definição, $f(x) \ge 0 \; \forall x$. Para verificarmos que a probabilidade total é igual a um, podemos realizar a seguinte integração por partes:

\begin{align*}
\int_{-\infty}^{x}f_{X}(x)\mathrm{d}x &= \int_{0}^{2}f_{X}(x)\mathrm{d}x \\
&= \int_{0}^{1}x \mathrm{d}x + \int_{1}^{2}(2-x)\mathrm{d}x \\
&= \frac{x^{2}}{2}\Big{|}_{0}^{1} + 2x \Big{|}_{1}^{2} - \frac{x^{2}}{2} \Big{|}_{1}^{2} \\
&= 1
\end{align*}

O que demonstra que $f_{X}(x)$ é densidade de probabilidade.

:::

::: {.conjecture}

Cada função de distribuição se corresponde com apenas uma distribuição? Não.

:::

::: {.proof}

Considere, por exemplo, que a variável aleatória $X \sim N(0,1)$. Logo, a sua função distribuição de probabilidade é dada por $f_{X}(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}$ e $\Phi(x)$ é sua acumulada. Vejamos que $X \sim N(0,1) \Longleftrightarrow -X \sim N(0,1)$:

Seja $\omega$ um possível valor de $-X$, devemos calcular $P(-X \le \omega)$ e provar que $P(-X \le \omega) = \Phi(\omega)$:

\begin{equation*}
P(-X \le \omega) = P(X \ge -\omega) = 1 - P(X \le \omega) = 1 - \Phi(-\omega) = 1 - (1 - \Phi(\omega)) = \Phi(\omega)
\end{equation*}

:::

## Variáveis aleatórias e $\sigma$-álgebra de Borel

Se $X$ é uma variável aleatória em $(\Omega, \mathcal{A}, P)$, cada evento $[X \le x] \in \mathcal{A} \; \forall x \in \mathbb{R}$. Isto é, $[X \in \mathcal{B}]$, onde $[X \in \mathcal{B}] = [X \le x]$ é um evento e $P(X \in \mathcal{B})$ é bem definido. No entanto, a operacionalidade do sistema $(\Omega, \mathcal{A},P)$ pode ser estendido a todo boreliano (ou seja, a todos os elementos da $\sigma$-álgebra de Borel, que é a menor $\sigma$-álgebra contendo os intervalos cujos comprimentos estejam bem definidos).

::: {.proposition}

Se $X$ é uma variável aleatória em $(\Omega,\mathcal{A},P)$, então o evento $[x \in \mathcal{B}] = \{\omega : \omega \in \Omega \text{ e } X(\omega) \in \mathcal{B}\}$ é um evento aleatório para todo $\mathcal{B}$ boreliano (ou seja, $[x \in B] \in \mathcal{A} \; \forall B \in \mathcal{B}$).

:::

Podemos ver que diferentes tipos de intervalos (leia-se borelianos) podem ser mostrados como pertencentes à $\sigma$-álgebra, de modo que variáveis aleatórias que operam sobre esses intervalos estarão bem definidas:

1. Se $B = (-\infty, b] \Rightarrow [X \in B] \in \mathcal{A}$ de acordo com a definição de variável aleatória;
2. Se $B = (a, \infty)$, podemos fazer $B = (-\infty, a]^{c}$. Como o evento $[X \le a] \in \mathcal{A}$ por definição, sendo $\mathcal{A}$ uma $\sigma$-álgebra, deve ocorrer que $[X \le a]^{c} = B \in \mathcal{A}$, ou seja, $B \in \mathcal{A}$;
3. Se $B = (a, b] \Rightarrow [X \in B] = [X \in (a,b]] = [X \le b] - [X \le a]$. Como $[X \le b] \in \mathcal{A}$ e $[X \le a] \in \mathcal{A}$, então $P(X \in B) = P(X \le b) - P(x \le a) = F_{X}(b) - F_{X}(a)$;
4. Se $B = (a,b) \Rightarrow B = \bigcup_{n=1}^{\infty}\left(a,b-\frac{1}{n}\right]$ Sabemos que os eventos $\left(a < X \le b - \frac{1}{n}\right] \in \mathcal{A}$ e as suas uniões também pertencem à $\mathcal{A}$. Quanto à probabilidade, temos $P(X \in B) = P\left(\bigcup_{n=1}^{\infty}\left(a < X \le b - \frac{1}{n}\right]\right) = \lim_{n \to \infty}P\left(\left(a < X \le b - \frac{1}{n}\right]\right) = \lim_{n \to \infty}F_{X}\left(b - \frac{1}{n}\right) - F_{X}(a) = F_{X}(b^{-}) - F_{X}(a)$;
5. Se $B = \bigcup_{i = 1}^{n}B_{i}:B_{i} \in \mathcal{A}\; \forall i$, e sendo os $B_{i}$'s disjuntos, temos que $[X \in B] = \bigcup_{i=1}^{n}[X \in B_{i}] \Rightarrow P([X \in B]) = \sum_{i=1}^{n}P(X \in B_{i})$.

Podemos assim reformular os axiomas de Kolmogorov:

- $Ax_{1}(K)$: $P_{X}(B) = P(X \in B) \ge 0$;
- $Ax_{2}(K)$: $P_{X}(\mathbb{R}) = P(X \in \mathbb{R}) = 1$;
- $Ax_{3}(K)$: Se $B_{1}, \ldots, B_{n} \in \mathcal{B}$, com $B_{i} \cap B_{j} = \emptyset \; \forall i \neq j \Rightarrow P_{X}(\bigcup B_{n}) = P(X \in \bigcup_{n}B_{n}) = P(\bigcup_{n}[X \in B_{n}]) = \sum_{n}P(X \in B_{n})$.

::: {.definition}

A probabilidade $P_{X}$ definida na $\sigma$-álgebra de Borel por $P_{X}(B) = P(X \in B)$ é a distribuição de $X$.

:::

::: {.proposition}

a) Se $X$ é uma variável aleatória discreta com valores em $\{x_{1},x_{2},\ldots\} \Rightarrow P_{X}(B) = \sum_{i:x_{i} \in B}P(x_{i})$;
b) Se $X$ é absolutamente contínua com densidade $f \Rightarrow P_{X}(B) = \int_{B}f_{X}dx$.

:::

## Variáveis contínuas

::: {.proposition}

Se $X \sim f_{X}, \; y = bx+c, \; b>0$ e $c \in \mathbb{R} \Rightarrow Y \sim f_{Y}$ onde $f_{Y}(y) = \frac{1}{b}f_{X}(\frac{y-c}{b}); y \in \mathbb{R}$, onde $c$ é dito um parâmetro de posição (muitas vezes de posição central) e $b$ um parâmetro de escala.

:::

### Exemplos

::: {.example name="Distribuição Normal"}

\begin{equation*}
f(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}} \Longrightarrow f_{\mu,\sigma}(x) = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}
\end{equation*}

Aqui, $\mu$ representa a média (posição central) da distribuição e $\sigma^{2}$ a sua variância.

:::

::: {.example name="Distribuição Cauchy"}

\begin{equation*}
f(x) = \frac{1}{\pi(1 + x^{2})} \Longrightarrow f_{b,M}(x) = \frac{1}{b}\frac{1}{\pi\left(1+\left(\frac{x-M}{b}\right)^{2}\right)} = \frac{b}{\pi(b^{2}+(x-M)^2)}
\end{equation*}

Neste caso, $M$ é a mediana da distribuição e $b$ representa a distância entre $M$ e o 1º quartil da distribuição.

:::

::: {.example name="Distribuições Exponencial e Gamma"}

Considere $g(x) = e^{-x} I_{0,\infty}(x)$. Sabemos que $g$ é uma distribuição de probabilidade pois:

\begin{equation*}
\begin{cases*}
g(x) \ge 0 \;\forall x \in (0,\infty) \\
\int_{0}^{\infty}e^{-x}dx = 1
\end{cases*}
\end{equation*}

Vamos agora incluir no formato do tipo exponencial um componente polinomial. Dado $\alpha > 0$, defina $g(x) = x^{\alpha - 1}e^{-x}$. Podemos ver que $g$ é integrável, de modo que:

\begin{align*}
\int_{0}^{\infty}g(x)dx &= \int_{0}^{\infty}x^{\alpha - 1}e^{-x}dx = \Gamma(\alpha) \\
f_{X}(x) &= \begin{cases}\frac{1}{\Gamma(\alpha)}x^{\alpha - 1}e^{-x} & x>0 \\ 0 & c.c.\end{cases}
\end{align*}

Defina agora $y = \frac{X}{\beta}$ onde $X \sim \text{Gamma}(\alpha,1)$ e $\beta > 0$. A densidade de $Y$ pode ser encontrada por meio de:

\begin{align*}
P(Y \le y) &= P\left(\frac{X}{\beta} \le y\right) = P(X \le \beta y) \Rightarrow F_{Y}(y) = F_{X}(\beta y) \\
f_{Y}(y) &= \beta f_{X}(\beta y) = \beta\frac{(\beta y)^{\alpha - 1}}{\Gamma(\alpha)}e^{-\beta y} = \frac{\beta^{\alpha}}{\Gamma(\alpha)}y^{\alpha - 1}e^{-\beta y}
\end{align*}

Nesse caso (conhecido como distribuição Gama) $\frac{1}{\beta}$ é um parâmetro de escala e $\alpha$ é um parâmetro de forma. Temos alguns casos especiais, como:

- Se $\alpha = 1\; : Y \sim \text{Exp}(\beta)$;
- Se $\alpha = \frac{n}{2}$, com $n$ inteiro e $\beta = \frac{1}{2} \;: Y \sim \chi^{2}(n)$

:::
